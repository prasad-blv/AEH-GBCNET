{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9257224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transforms as T\n",
    "import utils\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "LABEL_ENUM = {0: \"nrml\", 1: \"benign\", 2: \"malg\"} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d85e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BusiDataset(Dataset):\n",
    "    \"\"\" GB classification dataset. \"\"\"\n",
    "    def __init__(self, img_dir, df, labels, to_blur=True, blur_kernel_size=(1,1), sigma=0, img_transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = img_transforms\n",
    "        d = []\n",
    "        for label in labels:\n",
    "            key, cls = label.split(\",\")\n",
    "            val = df[key]\n",
    "            val[\"filename\"] = key\n",
    "            val[\"label\"] = int(cls)\n",
    "            d.append(val)\n",
    "        self.df = d\n",
    "        self.sigma = sigma\n",
    "        self.to_blur = to_blur\n",
    "        self.blur_kernel_size = blur_kernel_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        # Get the image\n",
    "        filename = self.df[idx][\"filename\"]\n",
    "        img_name = os.path.join(self.img_dir, filename)\n",
    "        image = cv2.imread(img_name)\n",
    "        if self.to_blur:\n",
    "            image = cv2.GaussianBlur(image, self.blur_kernel_size, self.sigma)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image)\n",
    "        label = torch.as_tensor(self.df[idx][\"label\"], dtype=torch.int64)\n",
    "        #cv2.imwrite(filename, image)\n",
    "        print\n",
    "        return img, label, filename\n",
    "\n",
    "\n",
    "class GbRawDataset(Dataset):\n",
    "    \"\"\" GB classification dataset. \"\"\"\n",
    "    def __init__(self, img_dir, df, labels, img_transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = img_transforms\n",
    "        d = []\n",
    "        for label in labels:\n",
    "            key, cls = label.split(\",\")\n",
    "            val = df[key]\n",
    "            val[\"filename\"] = key\n",
    "            val[\"label\"] = int(cls)\n",
    "            d.append(val)\n",
    "        self.df = d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        # Get the image\n",
    "        filename = self.df[idx][\"filename\"]\n",
    "        img_name = os.path.join(self.img_dir, filename)\n",
    "        image = cv2.imread(img_name)\n",
    "        if self.transforms:\n",
    "            img = self.transforms(image)\n",
    "        label = torch.as_tensor(self.df[idx][\"label\"], dtype=torch.int64)\n",
    "        #cv2.imwrite(filename, image)\n",
    "        print\n",
    "        return img, label, filename\n",
    "\n",
    "\n",
    "def crop_image(image, box, p):\n",
    "    x1, y1, x2, y2 = box\n",
    "    cropped_image = image[int((1-p)*y1):int((1+p)*y2), \\\n",
    "                            int((1-p)*x1):int((1+p)*x2)]\n",
    "    return cropped_image\n",
    "\n",
    "\n",
    "class GbDataset(Dataset):\n",
    "    \"\"\" GB classification dataset. \"\"\"\n",
    "    def __init__(self, img_dir, df, labels, is_train=True, to_blur=True, blur_kernel_size=(65,65), sigma=0, p=0.15, img_transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = img_transforms\n",
    "        self.to_blur = to_blur\n",
    "        self.blur_kernel_size = blur_kernel_size\n",
    "        self.sigma = sigma\n",
    "        self.is_train = is_train\n",
    "        d = []\n",
    "        for label in labels:\n",
    "            key, cls = label.split(\",\")\n",
    "            val = df[key]\n",
    "            val[\"filename\"] = key\n",
    "            val[\"label\"] = int(cls)\n",
    "            d.append(val)\n",
    "        self.df = d\n",
    "        self.p = p\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        # Get the image\n",
    "        filename = self.df[idx][\"filename\"]\n",
    "        img_name = os.path.join(self.img_dir, filename)\n",
    "        image = cv2.imread(img_name)\n",
    "        if self.to_blur:\n",
    "            image = cv2.GaussianBlur(image, self.blur_kernel_size, self.sigma)\n",
    "        image = crop_image(image, self.df[idx][\"Gold\"], self.p)\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        label = torch.as_tensor(self.df[idx][\"label\"], dtype=torch.int64)\n",
    "        return image, label, filename\n",
    "        \"\"\"\n",
    "        # Get the roi bbox\n",
    "        num_objs = len(self.df[idx][\"Boxes\"])\n",
    "        crps = [orig]\n",
    "        labels = [label]\n",
    "        for i in range(num_objs):\n",
    "            bbs = self.df[idx][\"Boxes\"][i]\n",
    "            crp_img = crop_image(image, bbs, 0.1)\n",
    "            #stack the predicted rois as different samples\n",
    "            if self.transforms:\n",
    "                crp_img = self.transforms(crp_img)\n",
    "            crps.append(crp_img)\n",
    "            labels.append(label)\n",
    "        if num_objs == 0:\n",
    "            #use the original img if no bbox predicted\n",
    "            #orig = self.transforms(image)\n",
    "            orig = orig.unsqueeze(0)\n",
    "            label = label.unsqueeze(0)\n",
    "        else:\n",
    "            orig = torch.stack(crps, 0)\n",
    "            label = torch.stack(labels, 0)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "class GbCropDataset(Dataset):\n",
    "    \"\"\" GB classification dataset. \"\"\"\n",
    "    def __init__(self, img_dir, df, labels, to_blur=True, blur_kernel_size=(65,65), sigma=16, p=0.15, img_transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = img_transforms\n",
    "        self.to_blur = to_blur\n",
    "        self.blur_kernel_size = (4*sigma+1, 4*sigma+1)#blur_kernel_size\n",
    "        self.sigma = sigma\n",
    "        self.p = p\n",
    "        d = []\n",
    "        for label in labels:\n",
    "            key, cls = label.split(\",\")\n",
    "            val = df[key]\n",
    "            val[\"filename\"] = key\n",
    "            val[\"label\"] = int(cls)\n",
    "            d.append(val)\n",
    "        self.df = d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        # Get the image\n",
    "        filename = self.df[idx][\"filename\"]\n",
    "        img_name = os.path.join(self.img_dir, filename)\n",
    "        image = cv2.imread(img_name)\n",
    "        #plt.imshow(image,cmap='gray')\n",
    "        #plt.show()\n",
    "        if self.to_blur:\n",
    "            image = cv2.GaussianBlur(image, self.blur_kernel_size, self.sigma)\n",
    "        #print(df.values())\n",
    "        #print()\n",
    "        orig = crop_image(image, self.df[idx][\"Gold\"], self.p)\n",
    "        #orig = torch.from_numpy(orig).long()\n",
    "        if self.transforms:\n",
    "            orig = self.transforms(orig)\n",
    "        # Get the roi bbox\n",
    "        num_objs = len(self.df[idx][\"Boxes\"])\n",
    "        label = torch.as_tensor(self.df[idx][\"label\"], dtype=torch.int64)\n",
    "        crps = []\n",
    "        labels = []\n",
    "        for i in range(num_objs):\n",
    "            bbs = self.df[idx][\"Boxes\"][i]\n",
    "            crp_img = crop_image(image, bbs, self.p)\n",
    "            #stack the predicted rois as different samples\n",
    "            if self.transforms:\n",
    "                crp_img = self.transforms(crp_img)\n",
    "            crps.append(crp_img)\n",
    "            labels.append(label)\n",
    "        if num_objs == 0:\n",
    "            #use the original img if no bbox predicted\n",
    "            #orig = self.transforms(image)\n",
    "            orig = orig.unsqueeze(0)\n",
    "            label = label.unsqueeze(0)\n",
    "        else:\n",
    "            orig = torch.stack(crps, 0)\n",
    "            label = torch.stack(labels, 0)\n",
    "        return orig, label, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac8370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    data_list, label_list, file_names = [], [], []\n",
    "    for _data,_label,_filename in batch:\n",
    "        data_list.append(_data)\n",
    "        label_list.append(_label)\n",
    "        file_names.append(_filename)\n",
    "    return data_list, label_list, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e0452b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0]), tensor([0]), tensor([1]), tensor([0, 0]), tensor([1]), tensor([1]), tensor([1]), tensor([1, 1]), tensor([0, 0]), tensor([1]), tensor([0]), tensor([0]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1, 1]), tensor([1, 1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]))\n",
      "torch.Size([1, 3, 224, 224])\n",
      "('im00049.jpg', 'im00748.jpg', 'im01229.jpg', 'im00730.jpg', 'im00203.jpg', 'im01031.jpg', 'im00868.jpg', 'im00300.jpg', 'im00422.jpg', 'im00497.jpg', 'im00134.jpg', 'im01150.jpg', 'im00662.jpg', 'im00061.jpg', 'im01237.jpg', 'im00984.jpg', 'im00095.jpg', 'im01155.jpg', 'im00303.jpg', 'im00719.jpg', 'im01097.jpg', 'im00741.jpg', 'im01254.jpg', 'im01193.jpg', 'im00824.jpg', 'im00772.jpg', 'im00707.jpg', 'im00059.jpg', 'im00088.jpg', 'im00075.jpg', 'im00918.jpg', 'im00437.jpg')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    VAL_IMG_DIR = \"C:/Users/Lakshmi vara prasad/Downloads/GBCU/imgs\"\n",
    "    VAL_JSON = \"C:/Users/Lakshmi vara prasad/Downloads/GBCU/roi_pred.json\"\n",
    "    labels = []\n",
    "    with open(\"C:/Users/Lakshmi vara prasad/Downloads/GBCU/train.txt\", \"r\") as f:\n",
    "        for e in f.readlines():\n",
    "            labels.append(e.strip())\n",
    "    with open(VAL_JSON, \"r\") as f:\n",
    "        df = json.load(f)\n",
    "    img_transforms = T.Compose([T.Resize((224,224)), T.ToTensor()])\n",
    "    dataset = GbCropDataset(VAL_IMG_DIR, df, labels, img_transforms = img_transforms)\n",
    "    loader = DataLoader(dataset, batch_size=32, collate_fn=utils.collate_fn)\n",
    "    images, labels, filename = next(iter(loader))\n",
    "    print(labels)\n",
    "    print(images[0].size())\n",
    "    print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdd2dfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neptune-client in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (0.16.15)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (8.1.3)\n",
      "Requirement already satisfied: future>=0.17.1 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (0.18.2)\n",
      "Requirement already satisfied: PyJWT in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (2.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (1.16.0)\n",
      "Requirement already satisfied: boto3>=1.16.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (1.26.30)\n",
      "Requirement already satisfied: packaging in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (21.3)\n",
      "Requirement already satisfied: bravado<12.0.0,>=11.0.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (11.0.3)\n",
      "Requirement already satisfied: Pillow>=1.1.6 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (9.2.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (1.4.4)\n",
      "Requirement already satisfied: swagger-spec-validator>=2.7.4 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (3.0.3)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (1.4.2)\n",
      "Requirement already satisfied: oauthlib>=2.1.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (3.2.1)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (1.26.12)\n",
      "Requirement already satisfied: GitPython>=2.0.8 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (3.1.29)\n",
      "Requirement already satisfied: requests>=2.20.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (2.28.1)\n",
      "Requirement already satisfied: requests-oauthlib>=1.0.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (1.3.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from neptune-client) (5.9.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from boto3>=1.16.0->neptune-client) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.30 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from boto3>=1.16.0->neptune-client) (1.29.30)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from boto3>=1.16.0->neptune-client) (0.6.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (2.8.2)\n",
      "Requirement already satisfied: simplejson in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (4.4.0)\n",
      "Requirement already satisfied: monotonic in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.6)\n",
      "Requirement already satisfied: msgpack in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.0.4)\n",
      "Requirement already satisfied: bravado-core>=5.16.1 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (5.17.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from click>=7.0->neptune-client) (0.4.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from GitPython>=2.0.8->neptune-client) (4.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from requests>=2.20.0->neptune-client) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from requests>=2.20.0->neptune-client) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from requests>=2.20.0->neptune-client) (3.4)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from packaging->neptune-client) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from pandas->neptune-client) (2022.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from pandas->neptune-client) (1.23.3)\n",
      "Requirement already satisfied: jsonref in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.0.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (5.0.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (22.1.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.12)\n",
      "Requirement already satisfied: isoduration in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (20.11.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.0)\n",
      "Requirement already satisfied: rfc3987 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.3.8)\n",
      "Requirement already satisfied: fqdn in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.1)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (2.3)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.1.4)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\lakshmi vara prasad\\python\\lib\\site-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install neptune-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f8c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transforms as T\n",
    "import utils\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from skimage import io, transform\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from dataloader import GbDataset, GbRawDataset, GbCropDataset\n",
    "from models import GbcNet \n",
    "# import neptune logger\n",
    "import neptune.new as neptune\n",
    "# Set plot style\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c756911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse():\n",
    "    parser = argparse.ArgumentParser(description='Process arguments')\n",
    "    parser.add_argument('--img_dir', dest=\"img_dir\", default=\"C:/Users/Lakshmi vara prasad/Downloads/GBCU/imgs\")\n",
    "    parser.add_argument('--set_dir', dest=\"set_dir\", default=\"C:/Users/Lakshmi vara prasad/Downloads/GBCU\")\n",
    "    parser.add_argument('--train_set_name', dest=\"train_set_name\", default=\"train.txt\")\n",
    "    parser.add_argument('--test_set_name', dest=\"test_set_name\", default=\"test.txt\")\n",
    "    parser.add_argument('--meta_file', dest=\"meta_file\", default=\"C:/Users/Lakshmi vara prasad/Downloads/GBCU/roi_pred.json\")\n",
    "    parser.add_argument('--epochs', dest=\"epochs\", default=10, type=int)\n",
    "    parser.add_argument('--lr', dest=\"lr\", default=5e-3, type=float)\n",
    "    parser.add_argument('--height', dest=\"height\", default=224, type=int)\n",
    "    parser.add_argument('--width', dest=\"width\", default=224, type=int)\n",
    "    parser.add_argument('--no_roi', action='store_true')\n",
    "    parser.add_argument('--pretrain', action='store_true')\n",
    "    parser.add_argument('--load_model', action='store_true')\n",
    "    parser.add_argument('--load_path', dest=\"load_path\", default=\"C:/Users/Lakshmi vara prasad/Downloads/gbcnet.pth\")\n",
    "    parser.add_argument('--save_dir', dest=\"save_dir\", default=\"C:/Users/Lakshmi vara prasad/Download/outputs\")\n",
    "    parser.add_argument('--save_name', dest=\"save_name\", default=\"gbcnet_1\")\n",
    "    parser.add_argument('--optimizer', dest=\"optimizer\", default=\"sgd\")\n",
    "    parser.add_argument('--batch_size', dest=\"batch_size\", default=32, type=int)\n",
    "    parser.add_argument('--att_mode', dest=\"att_mode\", default=\"1\")\n",
    "    parser.add_argument('--va', action=\"store_true\")\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f6689a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    \n",
    "    transforms = []\n",
    "    transforms.append(T.Resize((args.width, args.height)))\n",
    "    #transforms.append(T.RandomHorizontalFlip(0.25))\n",
    "    transforms.append(T.ToTensor())\n",
    "    img_transforms = T.Compose(transforms)\n",
    "    \n",
    "    val_transforms = T.Compose([T.Resize((args.width, args.height)),\\\n",
    "                                T.ToTensor()])\n",
    "\n",
    "    with open(args.meta_file, \"r\") as f:\n",
    "        df = json.load(f)\n",
    "\n",
    "    train_labels = []\n",
    "    t_fname = os.path.join(args.set_dir, args.train_set_name)\n",
    "    with open(t_fname, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            train_labels.append(line.strip())\n",
    "    val_labels = []\n",
    "    v_fname = os.path.join(args.set_dir, args.test_set_name)\n",
    "    with open(v_fname, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            val_labels.append(line.strip())\n",
    "    if args.no_roi:\n",
    "        train_dataset = GbRawDataset(args.img_dir, df, train_labels, img_transforms=img_transforms)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=5)\n",
    "        val_dataset = GbRawDataset(args.img_dir, df, val_labels, img_transforms=val_transforms)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=5)\n",
    "    else:\n",
    "        val_dataset = GbCropDataset(args.img_dir, df, val_labels, to_blur=False, img_transforms=val_transforms)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=5)\n",
    "\n",
    "    net = GbcNet(num_cls=3, pretrain=args.pretrain, att_mode=args.att_mode) \n",
    "\n",
    "    if args.load_model:\n",
    "        net.load_state_dict(torch.load(args.load_path))\n",
    "    net.net = net.net.float()#.cuda()\n",
    "\n",
    "    params = [p for p in net.parameters() if p.requires_grad]\n",
    "   \n",
    "    total_params = sum(p.numel() for p in net.parameters())\n",
    "    print(\"Total Param: \", total_params)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if args.optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(params, lr=args.lr, momentum=0.9, weight_decay=0.0005)\n",
    "    else:\n",
    "        optimizer = optim.Adam(params, lr=args.lr)\n",
    "    lr_sched = StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "    \n",
    "    os.makedirs(args.save_dir, exist_ok=True)\n",
    "\n",
    "    train_loss = []\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        if not args.no_roi:\n",
    "            if args.va:\n",
    "                if epoch <10:\n",
    "                    train_dataset = GbDataset(args.img_dir, df, train_labels, blur_kernel_size=(65,65), sigma=16, img_transforms=img_transforms)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, num_workers=5)#, collate_fn=utils.collate_fn)\n",
    "                elif epoch >=10 and epoch <15:\n",
    "                    train_dataset = GbDataset(args.img_dir, df, train_labels, blur_kernel_size=(33,33), sigma=8, img_transforms=img_transforms)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=1)#, collate_fn=utils.collate_fn)\n",
    "                elif epoch >=15 and epoch <20:\n",
    "                    train_dataset = GbDataset(args.img_dir, df, train_labels, blur_kernel_size=(17,17), sigma=4, img_transforms=img_transforms)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=1)#, collate_fn=utils.collate_fn)\n",
    "                elif epoch >=20 and epoch <25:\n",
    "                    train_dataset = GbDataset(args.img_dir, df, train_labels, blur_kernel_size=(9,9), sigma=2, img_transforms=img_transforms)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=1)#, collate_fn=utils.collate_fn)\n",
    "                elif epoch >=25 and epoch <30:\n",
    "                    train_dataset = GbDataset(args.img_dir, df, train_labels, blur_kernel_size=(5,5), sigma=1, img_transforms=img_transforms)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=1)#, collate_fn=utils.collate_fn)\n",
    "                else:\n",
    "                    train_dataset = GbDataset(args.img_dir, df, train_labels, to_blur=False, img_transforms=img_transforms)\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=1)#, collate_fn=utils.collate_fn)\n",
    "            else:\n",
    "                train_dataset = GbDataset(args.img_dir, df, train_labels, to_blur=False, img_transforms=img_transforms)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=1)#, collate_fn=utils.collate_fn)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        total_step = len(train_loader)\n",
    "        for images, targets, fnames in train_loader:\n",
    "            #images, targets = images.float().cuda(), targets.cuda()\n",
    "            images, targets = images.float(), targets\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs.cpu(), targets.cpu())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss.append(running_loss/total_step)\n",
    "       \n",
    "        y_true, y_pred = [], []\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            for images, targets, fname in val_loader:\n",
    "                #images, targets = images.float().cuda(), targets.cuda()\n",
    "                images, targets = images.float(), targets\n",
    "                if not args.no_roi:\n",
    "                    images = images.squeeze(0)\n",
    "                    outputs = net(images)\n",
    "                    _, pred = torch.max(outputs, dim=1)\n",
    "                    pred_label = torch.max(pred)\n",
    "                    pred_idx = pred_label.item()\n",
    "                    pred_label = pred_label.unsqueeze(0)\n",
    "                    y_true.append(targets.tolist()[0][0])\n",
    "                    y_pred.append(pred_label.item())\n",
    "                else:\n",
    "                    outputs = net(images)\n",
    "                    _, pred = torch.max(outputs, dim=1)\n",
    "                    pred_idx = pred.item()\n",
    "                    y_true.append(targets.tolist()[0])\n",
    "                    y_pred.append(pred.item())\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            cfm = confusion_matrix(y_true, y_pred)\n",
    "            spec = (cfm[0][0] + cfm[0][1] + cfm[1][0] + cfm[1][1])/(np.sum(cfm[0]) + np.sum(cfm[1]))\n",
    "            sens = cfm[2][2]/np.sum(cfm[2])\n",
    "            print('Epoch: [{}/{}] Train-Loss: {:.4f} Val-Acc: {:.4f} Val-Spec: {:.4f} Val-Sens: {:.4f}'\\\n",
    "                    .format(epoch+1, args.epochs, train_loss[-1], acc, spec, sens))\n",
    "\n",
    "            _name = \"%s_epoch_%s.pth\"%(args.save_name, epoch)\n",
    "            save_path = os.path.join(args.save_dir, _name)\n",
    "            torch.save(net.state_dict(), save_path)\n",
    "\n",
    "        net.train()\n",
    "        #lr_sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab98e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Param:  26903627\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    args = parse()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee187f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
